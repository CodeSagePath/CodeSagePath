{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeSagePath/CodeSagePath/blob/master/Deep_CNN_Image_Classifier_For_2D_Room_Layouts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup**"
      ],
      "metadata": {
        "id": "11oaaWuV5wrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# import zipfile\n",
        "# zip_path = '/content/ezyzip.zip'\n",
        "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall('/content')"
      ],
      "metadata": {
        "id": "K9fGuFKUzTpa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU') #shows all gpus available\n",
        "#this is telling tensorflow to limit the memory consumption\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "ZTQ0yNaR0LT8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Remove Bad Images**"
      ],
      "metadata": {
        "id": "N1lg0jCA51to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import imghdr"
      ],
      "metadata": {
        "id": "AZYFiF315LdG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm '/content/data/.DS_Store'\n",
        "data_dir = '/content/data'\n",
        "image_exts = ['jpeg', 'jpg', 'bmp', 'png']"
      ],
      "metadata": {
        "id": "eyv0OlSDEc6V",
        "outputId": "321f679b-3b53-4fad-ac2c-05b1f990f0c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/data/.DS_Store': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class in os.listdir(data_dir):\n",
        "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
        "        image_path = os.path.join(data_dir, image_class, image)\n",
        "        try:\n",
        "            img = cv2.imread(image_path)\n",
        "            tip = imghdr.what(image_path)\n",
        "            if tip not in image_exts:\n",
        "                print('Image not in ext list {}'.format(image_path))\n",
        "                os.remove(image_path)\n",
        "        except Exception as e:\n",
        "            print('Issue with image {}'.format(image_path))\n",
        "            # os.remove(image_path)"
      ],
      "metadata": {
        "id": "bk_vRclYEll1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "e011213c-631b-43c1-a57b-009ef7da4c1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-504fb4ff73c2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "JavHDzXNOl88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "D8XDpLMPOoO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building data pipeline\n",
        "data = tf.keras.utils.image_dataset_from_directory('/content/data')"
      ],
      "metadata": {
        "id": "SAQP1xiXN9RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iterator = data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "_ERFAFzUPKBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = data_iterator.next()"
      ],
      "metadata": {
        "id": "1EiXHS2vPr8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch[0].shape"
      ],
      "metadata": {
        "id": "vFZbJlMHRZrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class 1 = 2D Office Spaces\n",
        "# Class 0 = 2D Living Spaces\n",
        "batch[1]"
      ],
      "metadata": {
        "id": "42bswVd7RcYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "for index, img in enumerate(batch[0][:4]):\n",
        "    ax[index].imshow(img.astype(int))\n",
        "    ax[index].title.set_text(batch[1][index])"
      ],
      "metadata": {
        "id": "yPumBzDGPuop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocess Data**"
      ],
      "metadata": {
        "id": "fy-0d1DVS8T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling the data\n",
        "data = data.map(lambda x,y: ((x/255), y)) #scales all the pixel values to between 0 and 1, map function allows us to apply the scaling transformation as the data is accessed."
      ],
      "metadata": {
        "id": "2jRt3FOVRbvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "8f5NrVbGQCdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting data into training, validation, and test partition\n",
        "train_size = int(len(data)*.7) #used to train our model\n",
        "val_size = int(len(data)*.2) + 1 #used to evaluate our model during training and fine tune\n",
        "test_size = int(len(data)*.1) + 1 #used for post training evaluation\n",
        "print(len(data) == (train_size + val_size + test_size))"
      ],
      "metadata": {
        "id": "RqldDeQzTu87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data is already shuffled\n",
        "train = data.take(train_size)\n",
        "val = data.skip(train_size).take(val_size)\n",
        "test = data.skip(train_size+val_size).take(test_size)\n",
        "print(len(data) == len(train) + len(val) + len(test))"
      ],
      "metadata": {
        "id": "NcIhMRnGb3Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building The Deep Learning Model**"
      ],
      "metadata": {
        "id": "7Yo0WoHJet2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler"
      ],
      "metadata": {
        "id": "1jHjiTtueAy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "data_augmentation = Sequential([\n",
        "    RandomFlip(\"horizontal_and_vertical\"),\n",
        "    RandomRotation(0.2),\n",
        "    RandomZoom(0.2),\n",
        "])\n",
        "\n",
        "model = Sequential([\n",
        "    data_augmentation,  # Data augmentation layers\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, 256, 256, 3))  # Explicitly building the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "yajfL7b5fJEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "_dXBMeL0kVxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = 'logs'\n",
        "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    min_lr=0.00001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "hist = model.fit(\n",
        "    train,\n",
        "    epochs=30,\n",
        "    validation_data=val,\n",
        "    callbacks=[tensorboard_callback, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "id": "nVPhUa0yjXVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plot Performance**"
      ],
      "metadata": {
        "id": "eNmJJAUrwG_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mYMPkgITlISI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "fig.suptitle('Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qcazXngAwLt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate**"
      ],
      "metadata": {
        "id": "kp1Ru406wWkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
      ],
      "metadata": {
        "id": "BJFK-QqPwYsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precs = Precision()\n",
        "re = Recall()\n",
        "acc = BinaryAccuracy()\n",
        "\n",
        "for batch in test.as_numpy_iterator():\n",
        "    X, y = batch\n",
        "    yhat = model.predict(X)\n",
        "    precs.update_state(y, yhat)\n",
        "    re.update_state(y, yhat)\n",
        "    acc.update_state(y, yhat)"
      ],
      "metadata": {
        "id": "_ydbwZRpTPQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Precision: {precs.result().numpy()}, Recall: {re.result().numpy()}, Accuracy: {acc.result().numpy()}')"
      ],
      "metadata": {
        "id": "6UjEKLiPUF0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test**"
      ],
      "metadata": {
        "id": "u5HaDtpfwZIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgliving1 = cv2.imread('/content/data/test/test-livingspace1.jpg')\n",
        "imgliving2 = cv2.imread('/content/data/test/test-livingspace2.jpg')\n",
        "imgoffice1 = cv2.imread('/content/data/test/test-office1.jpg')\n",
        "imgoffice2 = cv2.imread('/content/data/test/test-office2.jpg')"
      ],
      "metadata": {
        "id": "MjR2jMG1bGHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(imgliving1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ndnMkdODwbOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_imgliving1 = tf.image.resize(imgliving1, (256, 256))\n",
        "resize_imgliving2 = tf.image.resize(imgliving2, (256, 256))\n",
        "resize_imgoffice1 = tf.image.resize(imgoffice1, (256, 256))\n",
        "resize_imgoffice2 = tf.image.resize(imgoffice2, (256, 256))\n",
        "\n",
        "plt.imshow(resize_imgliving1.numpy().astype(int))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0h67BOSDZ2Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.expand_dims(resize_imgliving1, 0)\n",
        "np.expand_dims(resize_imgliving2, 0)\n",
        "np.expand_dims(resize_imgoffice1, 0)\n",
        "np.expand_dims(resize_imgoffice2, 0)"
      ],
      "metadata": {
        "id": "yU9R9ymZcD0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_living1 = model.predict(np.expand_dims(resize_imgliving1/255, 0))\n",
        "yhat_living2 = model.predict(np.expand_dims(resize_imgliving2/255, 0))\n",
        "yhat_office1 = model.predict(np.expand_dims(resize_imgoffice1/255, 0))\n",
        "yhat_office2 = model.predict(np.expand_dims(resize_imgoffice2/255, 0))\n",
        "print(\"Living Space = 0 \\nOffice Space = 1\")\n",
        "print(f'Living Space Test #1: {yhat_living1[0][0]} \\nLiving Space Test #2: {yhat_living2[0][0]} \\nOffice Space Test #1: {yhat_office1[0][0]} \\nOffice Space Test #2: {yhat_office2[0][0]}')"
      ],
      "metadata": {
        "id": "pB3lCHyEb0pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "future considerations: make sure that when preprocessing data, remove all color, otherwise the model may form biases."
      ],
      "metadata": {
        "id": "SyD30TeJfZZL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_1pQuM5ucVMO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}